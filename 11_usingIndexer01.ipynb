{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation\n",
    "- Create Azure AI Services **multi-service account** in the same region as AI Search\n",
    "- In Azure OpenAI access control, add Azure AI Search as a **Cognitive Service OpenAI Contributor** role."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes import SearchIndexerClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    VectorSearch,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    VectorSearchProfile,\n",
    "    AzureOpenAIVectorizer,\n",
    "    AzureOpenAIVectorizerParameters,\n",
    "    SearchIndex,\n",
    "    SearchIndexerDataContainer,\n",
    "    SearchIndexerDataSourceConnection,\n",
    "    SplitSkill,\n",
    "    InputFieldMappingEntry,\n",
    "    OutputFieldMappingEntry,\n",
    "    AzureOpenAIEmbeddingSkill,\n",
    "    EntityRecognitionSkill,\n",
    "    KeyPhraseExtractionSkill,\n",
    "    SearchIndexerIndexProjection,\n",
    "    SearchIndexerIndexProjectionSelector,\n",
    "    SearchIndexerIndexProjectionsParameters,\n",
    "    IndexProjectionMode,\n",
    "    SearchIndexerSkillset,\n",
    "    CognitiveServicesAccountKey,\n",
    "    SemanticConfiguration,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticField,\n",
    "    SemanticSearch,\n",
    "    SearchIndexer\n",
    ")\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizableTextQuery, QueryType\n",
    "\n",
    "service_endpoint = os.environ[\"SEARCH_ENDPOINT\"] \n",
    "index_name = os.environ[\"SEARCH_INDEX_NAME_3\"]\n",
    "key = os.environ[\"SEARCH_KEY\"]\n",
    "credential = AzureKeyCredential(key) \n",
    "\n",
    "aoai_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "aoai_key = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
    "embedding_model = os.environ[\"AZURE_OPENAI_EMBEDDING_MODEL\"]\n",
    "\n",
    "connection_string = os.environ[\"STORAGE_CONN_STR\"]\n",
    "container_name = os.environ[\"CONTAINER_NAME\"]\n",
    "\n",
    "ai_multiservice_key = os.environ[\"AZURE_AI_MULTISERVICE_KEY\"]\n",
    "ai_multiservice_account_name = os.environ[\"AZURE_AI_MULTISERVICE_ACCOUNT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE AN INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a search index  \n",
    "index_name = index_name \n",
    "index_client = SearchIndexClient(endpoint=service_endpoint, credential=credential)  \n",
    "fields = [\n",
    "    SearchField(name=\"parent_id\", type=SearchFieldDataType.String),\n",
    "    SearchField(name=\"title\", type=SearchFieldDataType.String, analyzer_name=\"ja.microsoft\", filterable=True, facetable=True, searchable=True),\n",
    "    SearchField(name=\"chunk_id\", type=SearchFieldDataType.String, key=True, sortable=True, filterable=True, facetable=True, analyzer_name=\"keyword\"),\n",
    "    SearchField(name=\"chunk\", type=SearchFieldDataType.String, analyzer_name=\"ja.microsoft\", sortable=False, filterable=False, facetable=False),\n",
    "    SearchField(name=\"key_phrases\", type=SearchFieldDataType.String, analyzer_name=\"ja.microsoft\", filterable=True, facetable=True, searchable=True),\n",
    "    SearchField(name=\"text_vector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single), vector_search_dimensions=3072, vector_search_profile_name=\"myHnswProfile\")\n",
    "    ]  \n",
    "  \n",
    "# Configure the vector search configuration  \n",
    "vector_search = VectorSearch(  \n",
    "    algorithms=[  \n",
    "        HnswAlgorithmConfiguration(name=\"myHnsw\"),\n",
    "    ],  \n",
    "    profiles=[  \n",
    "        VectorSearchProfile(  \n",
    "            name=\"myHnswProfile\",  \n",
    "            algorithm_configuration_name=\"myHnsw\",  \n",
    "            vectorizer_name=\"myOpenAI\",  \n",
    "        )\n",
    "    ],  \n",
    "    vectorizers=[  \n",
    "        AzureOpenAIVectorizer(  \n",
    "            vectorizer_name=\"myOpenAI\",  \n",
    "            kind=\"azureOpenAI\",  \n",
    "            parameters=AzureOpenAIVectorizerParameters(  \n",
    "                resource_url=aoai_endpoint,  \n",
    "                deployment_name=embedding_model,\n",
    "                model_name=embedding_model\n",
    "            ),\n",
    "        ),  \n",
    "    ], \n",
    ")\n",
    "semantic_config = SemanticConfiguration(\n",
    "    name=\"default\",\n",
    "    prioritized_fields=SemanticPrioritizedFields(\n",
    "        title_field=SemanticField(field_name=\"title\"),\n",
    "        keywords_fields=[SemanticField(field_name=\"key_phrases\")],\n",
    "        content_fields=[SemanticField(field_name=\"chunk\")]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create the semantic settings with the configuration\n",
    "semantic_search = SemanticSearch(configurations=[semantic_config])\n",
    "\n",
    "# Create the search index\n",
    "index = SearchIndex(name=index_name, fields=fields, vector_search=vector_search, semantic_search=semantic_search)  \n",
    "result = index_client.create_or_update_index(index)  \n",
    "print(f\"{result.name} created\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE A DATASOURCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data source \n",
    "indexer_client = SearchIndexerClient(endpoint=service_endpoint, credential=credential)\n",
    "container = SearchIndexerDataContainer(name=container_name)\n",
    "data_source_connection = SearchIndexerDataSourceConnection(\n",
    "    name=\"prius-ds\",\n",
    "    type=\"azureblob\",\n",
    "    connection_string=connection_string,\n",
    "    container=container\n",
    ")\n",
    "data_source = indexer_client.create_or_update_data_source_connection(data_source_connection)\n",
    "\n",
    "print(f\"Data source '{data_source.name}' created or updated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE A SKILLSET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a skillset  \n",
    "skillset_name = \"prius-skillset\"\n",
    "\n",
    "split_skill = SplitSkill(  \n",
    "    description=\"Split skill to chunk documents\",  \n",
    "    text_split_mode=\"pages\",  \n",
    "    context=\"/document\",  \n",
    "    maximum_page_length=4000,  \n",
    "    page_overlap_length=800,  \n",
    "    inputs=[  \n",
    "        InputFieldMappingEntry(name=\"text\", source=\"/document/content\"),  \n",
    "    ],  \n",
    "    outputs=[  \n",
    "        OutputFieldMappingEntry(name=\"textItems\", target_name=\"pages\")  \n",
    "    ],  \n",
    ")  \n",
    "  \n",
    "embedding_skill = AzureOpenAIEmbeddingSkill(  \n",
    "    description=\"Skill to generate embeddings via Azure OpenAI\",  \n",
    "    context=\"/document/pages/*\",  \n",
    "    resource_url=aoai_endpoint,  \n",
    "    api_key=aoai_key,\n",
    "    deployment_name=embedding_model,  \n",
    "    model_name=embedding_model,\n",
    "    dimensions=3072,\n",
    "    inputs=[  \n",
    "        InputFieldMappingEntry(name=\"text\", source=\"/document/pages/*\"),  \n",
    "    ],  \n",
    "    outputs=[  \n",
    "        OutputFieldMappingEntry(name=\"embedding\", target_name=\"text_vector\")  \n",
    "    ],  \n",
    ")\n",
    "\n",
    "keyphrase_skill = KeyPhraseExtractionSkill(\n",
    "    description=\"Skill to extract Key Phrases\",\n",
    "    context=\"/document/pages/*\",\n",
    "    default_language_code=\"ja\",\n",
    "    inputs=[\n",
    "        InputFieldMappingEntry(name=\"text\", source=\"/document/pages/*\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        OutputFieldMappingEntry(name=\"keyPhrases\", target_name=\"key_phrases\")\n",
    "    ]\n",
    ")\n",
    "  \n",
    "index_projections = SearchIndexerIndexProjection(  \n",
    "    selectors=[  \n",
    "        SearchIndexerIndexProjectionSelector(  \n",
    "            target_index_name=index_name,  \n",
    "            parent_key_field_name=\"parent_id\",  \n",
    "            source_context=\"/document/pages/*\",  \n",
    "            mappings=[  \n",
    "                InputFieldMappingEntry(name=\"chunk\", source=\"/document/pages/*\"),  \n",
    "                InputFieldMappingEntry(name=\"text_vector\", source=\"/document/pages/*/text_vector\"),\n",
    "                InputFieldMappingEntry(name=\"key_phrases\", source=\"/document/pages/*/key_phrases\"),  \n",
    "                InputFieldMappingEntry(name=\"title\", source=\"/document/metadata_storage_name\"),  \n",
    "            ],  \n",
    "        ),  \n",
    "    ],  \n",
    "    parameters=SearchIndexerIndexProjectionsParameters(  \n",
    "        projection_mode=IndexProjectionMode.SKIP_INDEXING_PARENT_DOCUMENTS  \n",
    "    ),  \n",
    ") \n",
    "\n",
    "cognitive_services_account = CognitiveServicesAccountKey(key=ai_multiservice_key)\n",
    "\n",
    "skills = [split_skill, embedding_skill, keyphrase_skill]\n",
    "\n",
    "skillset = SearchIndexerSkillset(  \n",
    "    name=skillset_name,  \n",
    "    description=\"Skillset to chunk documents and generating embeddings\",  \n",
    "    skills=skills,  \n",
    "    index_projection=index_projections,\n",
    "    cognitive_services_account=cognitive_services_account\n",
    ")\n",
    "  \n",
    "client = SearchIndexerClient(endpoint=service_endpoint, credential=credential)  \n",
    "client.create_or_update_skillset(skillset)  \n",
    "print(f\"{skillset.name} created\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE AN INDEXER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an indexer  \n",
    "indexer_name = \"prius-indexer\" \n",
    "\n",
    "# For public access to storage accounts, set indexer_parameters to \"None\"\n",
    "#indexer_parameters = None\n",
    "indexer_parameters = {\n",
    "     \"configuration\": {\n",
    "         \"executionEnvironment\": \"private\"\n",
    "    }\n",
    "}\n",
    "\n",
    "indexer = SearchIndexer(  \n",
    "    name=indexer_name,  \n",
    "    description=\"Indexer to index documents and generate embeddings\",  \n",
    "    skillset_name=skillset_name,  \n",
    "    target_index_name=index_name,  \n",
    "    data_source_name=data_source.name,\n",
    "    parameters=indexer_parameters\n",
    ")  \n",
    "\n",
    "# Create and run the indexer  \n",
    "try:\n",
    "    indexer_client = SearchIndexerClient(endpoint=service_endpoint, credential=credential)  \n",
    "    indexer_result = indexer_client.create_or_update_indexer(indexer)  \n",
    "\n",
    "    print(f' {indexer_name} is created and running. Give the indexer a few minutes before running a query.')  \n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector Search using text-to-vector conversion of the query string\n",
    "query = \"PCS警告灯が点滅または点灯する場合の対処法\"  \n",
    "\n",
    "search_client = SearchClient(endpoint=service_endpoint, credential=credential, index_name=index_name)\n",
    "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=50, fields=\"text_vector\")\n",
    "  \n",
    "results = search_client.search(  \n",
    "    search_text=query,  \n",
    "    vector_queries= [vector_query],\n",
    "    select=[\"chunk\"],\n",
    "    top=1\n",
    ")  \n",
    "  \n",
    "for result in results:  \n",
    "    print(f\"Score: {result['@search.score']}\")\n",
    "    print(f\"Chunk: {result['chunk']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"PCS警告灯が点滅または点灯する場合の対処法\"  \n",
    "\n",
    "search_client = SearchClient(endpoint=service_endpoint, credential=credential, index_name=index_name)\n",
    "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=50, fields=\"text_vector\")\n",
    "\n",
    "results = list(search_client.search(  \n",
    "    search_text=query,  \n",
    "    vector_queries=[vector_query],\n",
    "    select=[\"title\", \"chunk\"],\n",
    "    query_type=QueryType.SEMANTIC, \n",
    "    semantic_configuration_name=\"default\",\n",
    "    search_fields=[\"chunk, key_phrases\"],\n",
    "    #query_caption=QueryCaptionType.EXTRACTIVE, \n",
    "    #query_answer=QueryAnswerType.EXTRACTIVE,\n",
    "    top=3\n",
    "))\n",
    "\n",
    "concatenated_documents = \"\"\n",
    "for doc in results:\n",
    "    print(\"Document title:\", {doc['title']})\n",
    "    concatenated_documents += f\"<DOCUMENT>\\nTitle: {doc['title']}\\ncontent: {doc['chunk']}\\n</DOCUMENT>\\n\"\n",
    "\n",
    "print(concatenated_documents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
