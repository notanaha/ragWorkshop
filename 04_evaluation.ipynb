{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "パフォーマンスと品質評価ツールの使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.evaluation import GroundednessProEvaluator, GroundednessEvaluator, RetrievalEvaluator, RelevanceEvaluator\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "#credential = DefaultAzureCredential()\n",
    "\n",
    "# For Groundedness Evaluator\n",
    "model_config = {\n",
    "    \"azure_endpoint\": os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    \"api_key\": os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "    \"azure_deployment\": os.environ.get(\"AZURE_OPENAI_CHAT_MODEL\"),\n",
    "    \"api_version\": os.environ.get(\"AZURE_OPENAI_API_VERSION\"),\n",
    "}\n",
    "\n",
    "# For Groundedness Pro Evaluator\n",
    "azure_ai_project = {\n",
    "    \"subscription_id\": os.environ.get(\"AZURE_SUBSCRIPTION_ID\"),\n",
    "    \"resource_group_name\": os.environ.get(\"AZURE_RESOURCE_GROUP\"),\n",
    "    \"project_name\": os.environ.get(\"AZURE_PROJECT_NAME\"),\n",
    "}\n",
    "tenant_id = os.environ.get(\"TENANT_ID\")\n",
    "credential = InteractiveBrowserCredential(tenant_id=tenant_id) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./answer_sample.md\", \"r\", encoding = 'utf-8') as f:\n",
    "    answer = f.read()\n",
    "with open(\"./context_sample.txt\", \"r\", encoding = 'utf-8') as f:\n",
    "    context = f.read()\n",
    "query = \"パーキングブレーキについて教えてください。\"\n",
    "\n",
    "query_response = dict(\n",
    "    query=query,\n",
    "    context=context,\n",
    "    response=answer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GroundednessEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'groundedness': 5.0, 'gpt_groundedness': 5.0, 'groundedness_reason': 'The RESPONSE is fully grounded in the CONTEXT, providing a thorough and accurate answer to the QUERY with all relevant details included.'}\n"
     ]
    }
   ],
   "source": [
    "# Initialzing Groundedness evaluator\n",
    "groundedness_eval = GroundednessEvaluator(model_config)\n",
    "\n",
    "# Running Groundedness Evaluator on a query and response pair\n",
    "groundedness_score = groundedness_eval(\n",
    "    **query_response\n",
    ")\n",
    "print(groundedness_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RetrievalEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'retrieval': 5.0, 'gpt_retrieval': 5.0, 'retrieval_reason': 'The context fully addresses the query with highly relevant information about the parking brake, and the most pertinent chunks are well-ranked at the top. This aligns with the definition of a Score of 5.'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_eval = RetrievalEvaluator(model_config)\n",
    "query_response = dict(query=query, context=context)\n",
    "\n",
    "relevance_score = retrieval_eval(**query_response)\n",
    "print(relevance_score)\n",
    "relevance_score[\"retrieval\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RelevanceEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'relevance': 4.0, 'gpt_relevance': 4.0, 'relevance_reason': 'The RESPONSE fully and accurately addresses the QUERY by providing detailed and relevant information about the parking brake, including its operation, warnings, and additional considerations. It is complete and directly relevant to the question.'}\n"
     ]
    }
   ],
   "source": [
    "relevance_eval = RelevanceEvaluator(model_config)\n",
    "query_response = dict(query=query, response=context)\n",
    "\n",
    "relevance_score = relevance_eval(**query_response)\n",
    "print(relevance_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPTIONAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groundedness Pro evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialzing Groundedness Pro evaluator\n",
    "# Supported regions are ueaastus2 and sweedencentral\n",
    "groundedness_pro_eval = GroundednessProEvaluator(azure_ai_project=azure_ai_project, credential=credential)\n",
    "\n",
    "groundedness_pro_score = groundedness_pro_eval(\n",
    "    **query_response\n",
    ")\n",
    "print(groundedness_pro_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
