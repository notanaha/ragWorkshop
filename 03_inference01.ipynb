{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\".env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SET VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoai_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "aoai_api_key = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
    "api_version = os.environ[\"AZURE_OPENAI_API_VERSION\"]\n",
    "\n",
    "aoai_client = openai.AzureOpenAI( \n",
    "    azure_endpoint=aoai_endpoint,\n",
    "    api_key=aoai_api_key,\n",
    "    api_version= api_version\n",
    ")\n",
    "    \n",
    "#chat_model: str = \"gpt-4-turbo-jp\"\n",
    "chat_model: str = os.environ[\"AZURE_OPENAI_CHAT_MODEL\"]\n",
    "embedding_model: str = os.environ[\"AZURE_OPENAI_EMBEDDING_MODEL\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#/*----------------*/\n",
    "#  gpt4_query      */\n",
    "#/*----------------*/\n",
    "def gpt4_query(messages, tools=None, tool_choice=None, model=chat_model):\n",
    "\n",
    "    response = aoai_client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    temperature=0,\n",
    "    max_tokens = 4000,\n",
    "    #response_format={ \"type\": \"json_object\" },\n",
    "    tools=tools,\n",
    "    tool_choice=tool_choice\n",
    "    )\n",
    "\n",
    "    response_message = response.choices[0].message\n",
    "    messages.append(response_message)\n",
    "\n",
    "    return response_message, messages\n",
    "\n",
    "\n",
    "def call_gpt4(messages, tools=None, tool_choice=None, user_context=None):\n",
    "\n",
    "    response_message, messages = gpt4_query(messages, tools=tools, tool_choice=tool_choice)\n",
    "\n",
    "    answer     = response_message.content\n",
    "    tool_calls = response_message.tool_calls\n",
    "    #print(\"answer:\", answer)\n",
    "    print(\"tool_calls:\", tool_calls)\n",
    "\n",
    "    if tool_calls:\n",
    "        checkandrun_function_calling(tool_calls, messages)\n",
    "        response_message, messages  = gpt4_query(messages)\n",
    "    else:\n",
    "        print(\"No tool calls were made by the model.\")\n",
    "\n",
    "    return response_message, messages\n",
    "\n",
    "\n",
    "def checkandrun_function_calling(tool_calls, messages, ft_content=''):\n",
    "    for tool_call in tool_calls:\n",
    "        function_name = tool_call.function.name\n",
    "        print(\"function_name: \", function_name)\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "        print(\"function_args: \", function_args)\n",
    "\n",
    "        if function_name == \"searchDocuments\":\n",
    "            function_response = searchDocuments(\n",
    "                query=function_args.get(\"query\")\n",
    "            )\n",
    "        else:\n",
    "            function_response = json.dumps({\"error\": \"Unknown function\"})\n",
    "\n",
    "        messages.append(\n",
    "            {\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"role\": \"tool\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response,\n",
    "            }\n",
    "        )  \n",
    "        ft_content += function_response\n",
    "            \n",
    "    return ft_content\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOOLS DEFINITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "\n",
    "service_endpoint = os.environ[\"SEARCH_ENDPOINT\"] \n",
    "key = os.environ[\"SEARCH_KEY\"]\n",
    "search_index_name = os.environ[\"SEARCH_INDEX_NAME\"]\n",
    "credential = AzureKeyCredential(key)\n",
    "\n",
    "search_client = SearchClient(endpoint=service_endpoint, index_name=search_index_name, credential=credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tenacity import retry, stop_after_attempt, wait_random_exponential\n",
    "from azure.search.documents.models import (\n",
    "    QueryAnswerType,\n",
    "    QueryCaptionType,\n",
    "    QueryType,\n",
    "    VectorizedQuery, \n",
    ")\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "def generate_embeddings(text, model, aoai_client):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return aoai_client.embeddings.create(input = [text], model=model).data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchDocuments(query, aoai_client=aoai_client, embedding_model=embedding_model, search_client=search_client):\n",
    "\n",
    "    vector_query = VectorizedQuery(vector=generate_embeddings(query, embedding_model, aoai_client), k_nearest_neighbors=3, fields=\"contentVector\")\n",
    "\n",
    "    results = list(search_client.search(  \n",
    "        search_text=query,  \n",
    "        vector_queries=[vector_query],\n",
    "        select=[\"category\", \"title\", \"content\"],\n",
    "        query_type=QueryType.SEMANTIC, \n",
    "        semantic_configuration_name=\"default\",\n",
    "        #query_caption=QueryCaptionType.EXTRACTIVE, \n",
    "        #query_answer=QueryAnswerType.EXTRACTIVE,\n",
    "        top=3\n",
    "    ))\n",
    "\n",
    "    concatenated_documents = \"\"\n",
    "    for doc in results:\n",
    "        print(\"Document title:\", {doc['title']})\n",
    "        concatenated_documents += f\"<DOCUMENT>\\nCategory Name: {doc['category']}\\nTitle: {doc['title']}\\nContent: {doc['content']}\\n</DOCUMENT>\\n\"\n",
    "    \n",
    "    #concatenated_documents += '\\n' + user_context\n",
    "    return concatenated_documents\n",
    "\n",
    "\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"searchDocuments\",\n",
    "            \"description\": \"Use this to search for documents relevant to the query\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"query string to search for documents. Use the query as it is.\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"query\"],\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./01_businessSupport_sys_msg01.txt\", \"r\", encoding = 'utf-8') as f:\n",
    "    system_message = f.read()\n",
    "\n",
    "user_context = \"パーキングブレーキについて教えてください。\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function Calling のあるケース"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "messages.append({\"role\": \"system\",\"content\": system_message})\n",
    "messages.append({\"role\": \"user\", \"content\": user_context})\n",
    "response_message, messages = call_gpt4(messages, tools=tools, tool_choice='auto', user_context=user_context)\n",
    "print(response_message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "さらに質問"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append({\"role\": \"user\",\"content\": \"Search Index からいくつのドキュメントが得られましたか\"})\n",
    "response_message, messages = call_gpt4(messages, tools=tools, tool_choice='auto')\n",
    "print(response_message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
